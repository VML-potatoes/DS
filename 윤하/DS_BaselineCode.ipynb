{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Base Line Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import문 - Import 추가로 할게 있다면 여기다가 해주세요\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수선언은 여기에 해주면 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코딩 / 라벨링함수\n",
    "def encode_and_transform_datas(df):\n",
    "    # 1. 라벨 인코딩할 열들 지정\n",
    "    label_cols = ['Card Brand', 'Card Type', 'Error Message', 'Is Fraud?']\n",
    "    \n",
    "    # 2. 각 열에 대해 라벨 인코딩 수행\n",
    "    label_encoders = {}\n",
    "    for col in label_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le  # 나중에 필요하면 인코더 저장 (복원할 때 사용 가능)\n",
    "    \n",
    "    # 3. 날짜 데이터를 8자리 숫자로 변환\n",
    "    # 'Expires' 변환 (MM/YYYY -> YYYYMMDD)\n",
    "    df['Expires'] = df['Expires'].apply(lambda x: x.split('/')[1] + x.split('/')[0] + '01')\n",
    "    \n",
    "    # 'Acct Open Date' 변환 (MM/YYYY -> YYYYMMDD)\n",
    "    df['Acct Open Date'] = df['Acct Open Date'].apply(lambda x: x.split('/')[1] + x.split('/')[0] + '01')\n",
    "    \n",
    "    # 날짜 형식을 int 타입으로 변환\n",
    "    df['Expires'] = df['Expires'].astype(int)\n",
    "    df['Acct Open Date'] = df['Acct Open Date'].astype(int)\n",
    "    \n",
    "    # 인코딩된 데이터프레임 반환\n",
    "    return df\n",
    "#Is Fraud : Yes-1, No-0으로 Labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation Matrix 출력함수\n",
    "def correlation_write(df, path='datas/파생/correlation_matrix.csv'):\n",
    "    # 상관관계 계산\n",
    "    correlation_matrix = df.corr()\n",
    "    \n",
    "    # 상관관계 결과를 CSV로 저장\n",
    "    correlation_matrix.to_csv(path)\n",
    "    \n",
    "    # 히트맵 그리기\n",
    "    plt.figure(figsize=(10, 8)) \n",
    "    plt.title(\"Correlation Heatmap\", fontsize=16)\n",
    "    \n",
    "    # Seaborn 히트맵 사용 (각 칸에 상관계수 표시)\n",
    "    sns.heatmap(\n",
    "        correlation_matrix, \n",
    "        annot=True,          # 상관계수 표시\n",
    "        cmap='coolwarm', \n",
    "        linewidths=0.5, \n",
    "        fmt=\".2f\",           # 소수점 둘째 자리까지 표시\n",
    "        annot_kws={\"size\": 10} # 상관계수 숫자의 글꼴 크기 지정\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report, Confusion Matrix 출력함수\n",
    "def print_classification_report_and_confusion_matrix(model, X_test, y_test):\n",
    "    # 예측값 생성\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 정확도 출력\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # 분류 리포트 출력 (Precision, Recall, F1-score 등)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix 출력\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    matrix = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    matrix.plot(cmap='coolwarm')\n",
    "    for text in matrix.text_.ravel():\n",
    "        text.set_color(\"black\")\n",
    "    plt.grid(False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---  \n",
    "\n",
    "### 여기서부터가 찐구현\n",
    "#### 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('datas/train.csv')\n",
    "encode_and_transform_datas(train_data)\n",
    "print(train_data.columns)\n",
    "correlation_write(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train / Test Dataset 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['Is Fraud?'])\n",
    "y = train_data['Is Fraud?']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "class_weight ='balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l2',fit_intercept=False,class_weight='balanced',max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_classification_report_and_confusion_matrix(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Random Forest\n",
    "\n",
    "마찬가지로 아래의 class_weight='balanced'를 통해 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(class_weight='balanced',random_state=42)\n",
    "rf.fit(X_train,y_train)\n",
    "print_classification_report_and_confusion_matrix(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest는 자체적으로 Feature Importance를 추출할 수 있음 - 이에 대한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest 결과물 -> Feature Importance 추출\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "# 특성 이름과 중요도를 함께 보기 (X_train이 DataFrame일 때)\n",
    "feature_names = X_train.columns  # X_train이 Pandas DataFrame일 때\n",
    "feature_importances = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "\n",
    "# 중요도가 높은 순서대로 정렬\n",
    "feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "svm = make_pipeline(StandardScaler(),LinearSVC(penalty='l1',class_weight='balanced'))\n",
    "svm.fit(X_train,y_train)\n",
    "print_classification_report_and_confusion_matrix(svm, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
